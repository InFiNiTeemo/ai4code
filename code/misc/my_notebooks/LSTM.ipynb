{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb592be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from dataset import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from model import *\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "from metrics import *\n",
    "import torch\n",
    "import argparse\n",
    "import copy\n",
    "\n",
    "\n",
    "import pynvml\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)   #gpu_id\n",
    "meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb88d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./outputs\"):\n",
    "    os.mkdir(\"./outputs\")\n",
    "data_dir = Path('..//input/')\n",
    "\n",
    "train_mark_path = './data/train_mark.csv'\n",
    "train_features_path = \"./data/train_fts.json\"\n",
    "val_mark_path = './data/val_mark.csv'\n",
    "val_features_path = './data/val_fts.json'\n",
    "val_path = \"./data/val.csv\"\n",
    "model_name_or_path =\"microsoft/codebert-base\"\n",
    "\n",
    "md_max_len = 512\n",
    "total_max_len = 48\n",
    "batch_size= 1\n",
    "accumulation_steps=1\n",
    "epochs=1\n",
    "n_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_mark = pd.read_csv(train_mark_path).drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n",
    "train_fts = json.load(open(train_features_path))\n",
    "val_df_mark = pd.read_csv(val_mark_path).drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n",
    "val_fts = json.load(open(val_features_path))\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "order_df = pd.read_csv(\"../input/train_orders.csv\").set_index(\"id\")\n",
    "#df_orders = pd.read_csv(\n",
    "#    data_dir / 'train_orders.csv',\n",
    "#    index_col='id',\n",
    "#    squeeze=True,\n",
    "#).str.split()\n",
    "\n",
    "order = pd.read_csv(\n",
    "    data_dir / 'train_orders.csv'\n",
    ")\n",
    "train_path = './data/train.csv'\n",
    "val_path = './data/val.csv'\n",
    "val_df = pd.read_csv(val_path)\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "full_df = pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = train_df_mark[train_df_mark['cell_type']=='markdown'].groupby(\"id\").count()['cell_id']\n",
    "# tmp.apply(lambda x: x**2).sum()/len(tmp) # = 539\n",
    "# tmp.mean() # = 15.56\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(df):\n",
    "    md_dict = dict(zip(df[\"cell_id\"].values, df['source'].values))\n",
    "    return md_dict\n",
    "\n",
    "md_dict = get_dict(full_df[full_df['cell_type']=='markdown'])\n",
    "cd_dict = get_dict(full_df[full_df['cell_type']=='code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(md_dict), len(cd_dict)\n",
    "#len(train_df_mark), len(train_df), len(val_df_mark), len(val_df)\n",
    "#order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c482db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "x = 1<<32\n",
    "seed = 42\n",
    "def transform(row):\n",
    "    \n",
    "    cell_ids = list(row[\"cell_order\"].split())\n",
    "    md_ids = []\n",
    "    cell_shuffle = []\n",
    "    md_mask = []\n",
    "    for cell_id in cell_ids:\n",
    "        if cell_id in md_dict:\n",
    "            cell_shuffle.append(0)\n",
    "            md_ids.append(cell_id)\n",
    "            md_mask.append(1)\n",
    "        else:\n",
    "            cell_shuffle.append(cell_id)\n",
    "            md_mask.append(0)\n",
    "    length = len(md_ids)\n",
    "    _hash = hash(row[\"cell_order\"])*seed % x\n",
    "    permutation = np.arange(length)\n",
    "    #permutation = np.random.RandomState(seed=_hash).permutation(length)\n",
    "    i = 0\n",
    "    for j in range(len(cell_shuffle)):\n",
    "        if cell_shuffle[j] == 0:\n",
    "            cell_shuffle[j] = cell_ids[permutation[i]]\n",
    "            i+=1\n",
    "    \n",
    "    return pd.Series([row.id, cell_shuffle, permutation, md_mask, len(md_mask)], index=['id', 'cell_shuffle', 'permutation', 'md_mask', 'md_len'])\n",
    "\n",
    "order = order.apply(transform, axis=1)\n",
    "order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ids =   train_df[\"id\"].unique()\n",
    "train_order = order[order[\"id\"].isin(tr_ids)]\n",
    "val_order  = order[~(order[\"id\"].isin(tr_ids))]\n",
    "train_df = train_df.set_index(\"cell_id\", drop=True)\n",
    "val_df = val_df.set_index(\"cell_id\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7854db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_order.head()\n",
    "# val_order.head()\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593912d7",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order.head()\n",
    "#row = order.iloc[1]\n",
    "#for cell_id in row.cell_shuffle:\n",
    "#    print(cell_id)\n",
    "#    print(train_df.loc[cell_id].source)\n",
    "#    print(\"\\n\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ccef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "#row = train_order.iloc[1]\n",
    "#cells = row.cell_shuffle\n",
    "#[train_df.loc[cell_id].source for cell_id in cells]\n",
    "#inputs = tokenizer.batch_encode_plus(\n",
    "#            [train_df.loc[cell_id].source for cell_id in cells],\n",
    "#            add_special_tokens=True,\n",
    "#            max_length=total_max_len,\n",
    "#            padding=\"max_length\",\n",
    "#            # return_token_type_ids=True,\n",
    "#            truncation=True\n",
    "#        )\n",
    "#ids = torch.LongTensor(inputs['input_ids'])\n",
    "#mask = torch.LongTensor(inputs['attention_mask'])\n",
    "#md_mask = torch.LongTensor(row.md_mask)\n",
    "#permutation = torch.LongTensor(row.permutation)\n",
    "\n",
    "        \n",
    "#print(\"ids:\", ids.size())\n",
    "#print(\"mask:\", mask.size())\n",
    "#print(\"md_mask:\", md_mask.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkdownDataset(Dataset):\n",
    "    def __init__(self, order_df, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.order_df = order_df # .sort_values(by=['md_len','id'], ascending=False)\n",
    "        self.df = df\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.order_df.iloc[index]\n",
    "        cells = row.cell_shuffle\n",
    "\n",
    "        # print(\"index: \"+ str(index))\n",
    "\n",
    "        inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(self.df.loc[cell_id].source) for cell_id in cells],\n",
    "            # None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.total_max_len,\n",
    "            padding=\"max_length\",\n",
    "            # return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        ids = torch.LongTensor(inputs['input_ids'])\n",
    "        mask = torch.LongTensor(inputs['attention_mask'])\n",
    "        md_mask = torch.LongTensor(row.md_mask)\n",
    "        permutation = torch.LongTensor(row.permutation)\n",
    "    \n",
    "        length = len(md_mask)\n",
    "        \n",
    "        #print(\"ids:\", ids.size())\n",
    "        #print(\"mask:\", mask.size())\n",
    "        #print(\"md_mask:\", md_mask.size())\n",
    "        #return torch.FloatTensor([length])\n",
    "        return ids, mask, permutation, md_mask, length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.order_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79675639",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MarkdownDataset(train_order, train_df, model_name_or_path=model_name_or_path, md_max_len=md_max_len,\n",
    "                           total_max_len=total_max_len, fts=train_fts)\n",
    "val_ds = MarkdownDataset(val_order, val_df, model_name_or_path=model_name_or_path, md_max_len=md_max_len,\n",
    "                         total_max_len=total_max_len, fts=val_fts)\n",
    "# 每次shuffle均不同\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=n_workers,\n",
    "                          pin_memory=False, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=n_workers,\n",
    "                        pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f80d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cpu()\n",
    "HIDDEN_SIZE = 768\n",
    "class BersonModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(BersonModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.decoder = nn.LSTM(input_size=HIDDEN_SIZE, hidden_size=HIDDEN_SIZE, num_layers=1, batch_first=True)\n",
    "        self.top = nn.Linear(HIDDEN_SIZE+2, 1)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.layernorm = nn.LayerNorm(2)\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "\n",
    "    def forward(self, ids, mask, order, md_mask, length):\n",
    "        \"\"\"\n",
    "        :param ids:\n",
    "        :param mask:\n",
    "        :param orders:\n",
    "        :param type: 0 for code, 1 for md\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ids = ids.squeeze(0) # [:8,:]\n",
    "        mask = mask.squeeze(0) # [:8,:]\n",
    "        order = order.squeeze(0)\n",
    "        md_mask = md_mask.squeeze(0)\n",
    "        length = length.squeeze(0)\n",
    "        # print(\"ids:\", ids.size())\n",
    "        #print(\"md_mask:\", md_mask.size())\n",
    "        #rint(\"length[:\", length[0])\n",
    "        \n",
    "        \n",
    "        #print(torch.cuda.memory_allocated(device=0) / (1024 * 1024))#0表示显卡号\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"size:\",ids.size()[0])\n",
    "        def get_batch():\n",
    "            q = 16\n",
    "            l = []\n",
    "            while q < length+16:\n",
    "                q_ids = ids[q-16:q, :]\n",
    "                q_mask = mask[q-16:q, :]\n",
    "                t = self.model(q_ids, q_mask)[1]\n",
    "                q += 16\n",
    "                l.append(t)\n",
    "            return torch.cat(l, 0)\n",
    "        \"\"\"\n",
    "        \n",
    "        def get_batch():\n",
    "            return self.model(ids, mask)[0][:,[0],:]\n",
    "        \n",
    "        if length > 64:\n",
    "            with torch.no_grad():\n",
    "                x = get_batch()\n",
    "        else:\n",
    "            x = get_batch()\n",
    "        del ids, mask\n",
    "        \n",
    "        \n",
    "        x = torch.swapaxes(x, 0, 1)\n",
    "        # print(\"x:\", x.size())\n",
    "        \n",
    "        # hn -> (Layer, batch, hiddenstate)\n",
    "        cn = torch.sum(x, 1).cuda().unsqueeze(1)\n",
    "        #print(\"cn:\", cn.size())\n",
    "        hn = torch.zeros_like(cn).cuda()\n",
    "        hcn = (hn, cn)\n",
    "        \n",
    "        md_len = len(order)\n",
    "        # print(\"hn:\", hn.size())\n",
    "        # x = self.model(ids, mask)[1]\n",
    "        # print(torch.cuda.memory_allocated(device=0) / (1024 * 1024))#0表示显卡号\n",
    "        \n",
    "        md_pos = [idx for idx, i in enumerate(md_mask) if i==1]\n",
    "        # print(\"md_pos:\", md_pos)\n",
    "        # print(\"md_mask:\", md_mask)\n",
    "        # print(\"order:\", order)\n",
    "        md_pool = torch.swapaxes(x[:, md_pos, :], 0, 1)\n",
    "        # print(\"md_num:\",md_len)\n",
    "        # print(\"md_pool:\", md_pool.size())\n",
    "        loss = 0\n",
    "        j, idx = 0, 0\n",
    "        \n",
    "        # step = 1./md_len\n",
    "        # gt_loc = torch.arange(0, 1+step, step)[:md_len].cuda()\n",
    "        # assert len(gt_loc) == md_len\n",
    "        \n",
    "        for i in range(length):\n",
    "            if md_mask[i] == 1:\n",
    "                idx = order[j]  \n",
    "                # construct hcn for batch\n",
    "                hn, cn = hcn\n",
    "                hn = torch.tile(hn, (1, md_len, 1))\n",
    "                cn = torch.tile(cn, (1, md_len, 1))\n",
    "                t_hcn = (hn, cn)\n",
    "                \n",
    "                t_x, t_hcn = self.decoder(md_pool, t_hcn)\n",
    "                # t_x: (n, 1, h)\n",
    "                feats = torch.tensor([i*1.0/length, j*1.0/md_len], dtype=t_x.dtype).unsqueeze(0).unsqueeze(1).cuda()\n",
    "                feats = torch.tile(feats, (t_x.size()[0], t_x.size()[1],1))\n",
    "                t_x = torch.cat((t_x,feats), 2)\n",
    "                #print(\"t_x:\", t_x.size(), \"  idx:\", idx)\n",
    "                # torch.cat(torch.tensor(i*1.0/length, dtype=t_x.dtype), 2)\n",
    "                t_x = self.top(self.dropout(t_x))\n",
    "                # print(\"t_x:\", t_x.size(), \"  idx:\", idx)\n",
    "                output = self.softmax(t_x).squeeze(2).squeeze(1)\n",
    "                \n",
    "                gt = torch.zeros_like(output).cuda()\n",
    "                gt[idx] = 1.\n",
    "                # print(\"output:\",output)\n",
    "                # print(\"gt:\", gt)\n",
    "                loss += self.loss(output, gt)\n",
    "                # print(torch.square(gt_loc - torch.tensor(j*1.0/md_len, dtype=float).cuda()))\n",
    "                # loss += torch.sum(torch.square(gt_loc - torch.tensor(j*1.0/md_len, dtype=float).cuda()) * output)\n",
    "                j += 1\n",
    "            # print(\"test:\", x[:, [i], :].size())\n",
    "            output, hcn = self.decoder(x[:, [i], :], hcn)\n",
    "        \n",
    "                \n",
    "        \n",
    "        ## concat\n",
    "        loss /= md_len\n",
    "        # print(\"loss:\", loss)\n",
    "\n",
    "        # lstm\n",
    "        #hn = \n",
    "        #hcn = \n",
    "        #for t in range():\n",
    "        #    output, hcn = self.decoder(x, hcn) # hcn = (hidden_state, cell_state)\n",
    "        # loss\n",
    "        # loss = 1\n",
    "\n",
    "        ## sentence order\n",
    "\n",
    "        ## coherence\n",
    "        return loss\n",
    "    \n",
    "    def beam_search(self, ids, mask, order, md_mask, length, k=5):\n",
    "        \"\"\"\n",
    "        :param ids:\n",
    "        :param mask:\n",
    "        :param orders:\n",
    "        :param type: 0 for code, 1 for md\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ids = ids.squeeze(0) # [:8,:]\n",
    "        mask = mask.squeeze(0) # [:8,:]\n",
    "        order = order.squeeze(0)\n",
    "        md_mask = md_mask.squeeze(0)\n",
    "        length = length.squeeze(0)\n",
    "        \n",
    "        # print(\"ids:\", ids.size())\n",
    "        #print(\"md_mask:\", md_mask.size())\n",
    "        #rint(\"length[:\", length[0])\n",
    "\n",
    "\n",
    "        #print(torch.cuda.memory_allocated(device=0) / (1024 * 1024))#0表示显卡号\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"size:\",ids.size()[0])\n",
    "        def get_batch():\n",
    "          q = 16\n",
    "          l = []\n",
    "          while q < length+16:\n",
    "              q_ids = ids[q-16:q, :]\n",
    "              q_mask = mask[q-16:q, :]\n",
    "              t = self.model(q_ids, q_mask)[1]\n",
    "              q += 16\n",
    "              l.append(t)\n",
    "          return torch.cat(l, 0)\n",
    "        \"\"\"\n",
    "\n",
    "        def get_batch():\n",
    "            return self.model(ids, mask)[0][:,[0],:]\n",
    "        \n",
    "        if length > 64:\n",
    "            with torch.no_grad():\n",
    "                x = get_batch()\n",
    "        else:\n",
    "            x = get_batch()\n",
    "        del ids, mask\n",
    "        \n",
    "        \n",
    "        x = torch.swapaxes(x, 0, 1)\n",
    "        # print(\"x:\", x.size())\n",
    "        \n",
    "        # hn -> (Layer, batch, hiddenstate)\n",
    "        cn = torch.sum(x, 1).cuda().unsqueeze(1)\n",
    "        #print(\"cn:\", cn.size())\n",
    "        hn = torch.zeros_like(cn).cuda()\n",
    "        hcn = (hn, cn)\n",
    "\n",
    "        md_len = len(order)\n",
    "        # print(\"hn:\", hn.size())\n",
    "        # x = self.model(ids, mask)[1]\n",
    "        # print(torch.cuda.memory_allocated(device=0) / (1024 * 1024))#0表示显卡号\n",
    "\n",
    "        md_pos = [idx for idx, i in enumerate(md_mask) if i==1]\n",
    "        # (md_len, 1, h)\n",
    "        md_pool = torch.swapaxes(x[:, md_pos, :], 0, 1)\n",
    "        loss = 0\n",
    "        j, idx = 0, 0\n",
    "        # value, hcn, used\n",
    "        queue = [(0, hcn, torch.FloatTensor([1]*md_len), [])]\n",
    "        nxt_queue = []\n",
    "\n",
    "        for i in range(length):\n",
    "            if md_mask[i] == 1:\n",
    "                for score, hcn, mask, res in queue:\n",
    "                    # construct hcn for batch\n",
    "                    hcn = (torch.tile(hcn[0], (1, md_len, 1)), torch.tile(hcn[1], (1, md_len, 1)))\n",
    "                    # masked select for dim 1 \n",
    "                    # hcn_mask = mask.unsqueeze(0).unsqueeze(2)\n",
    "                    # hcn_mask = torch.tile(hcn_mask, (hcn[0].size()[0], 1, hcn[0].size()[2]))\n",
    "                    # print(\"masked_selected:\", torch.masked_select(hcn[0], hcn_mask).size())\n",
    "                    # hcn = (torch.masked_select(hcn[0], hcn_mask).reshape(hcn[0].size()[0],-1,hcn[0].size()[2]),\n",
    "                    #        torch.masked_select(hcn[1], hcn_mask).reshape(hcn[0].size()[0],-1,hcn[0].size()[2]))\n",
    "                    # print(\"md_pool size：\", md_pool.size())\n",
    "                    \n",
    "                    # md_pool_mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "                    # md_pool_mask = torch.tile(md_pool_mask, (1,1,md_pool.size()[2]))\n",
    "                    # masked select for dim 0\n",
    "                    # t_x = torch.masked_select(md_pool, md_pool_mask).reshape(-1,md_pool.size()[1],md_pool.size()[2])\n",
    "                    # print(\"t_x:\", t_x.size(), \"  idx:\", idx)\n",
    "                    t_x, hcn = self.decoder(md_pool, hcn)\n",
    "                    # x: (n, 1, h)\n",
    "                    feats = torch.tensor([i*1.0/length, j*1.0/md_len], dtype=t_x.dtype).unsqueeze(0).unsqueeze(1).cuda()\n",
    "                    feats = torch.tile(feats, (t_x.size()[0], t_x.size()[1],1))\n",
    "                    t_x = torch.cat((t_x,feats), 2)\n",
    "                    \n",
    "                    t_x = self.top(self.dropout(t_x)).squeeze(2).squeeze(1) * mask.cuda()\n",
    "                    # print(t_x)\n",
    "                    t_x = torch.where(t_x != 0.0, t_x, torch.tensor(-1e3, dtype=t_x.dtype).cuda())\n",
    "                    output = self.softmax(t_x)\n",
    "                    \n",
    "                    # print(\"output:\",output.size(), output)\n",
    "                    values, indexes = torch.topk(output, min(k, len(mask)))\n",
    "                    \n",
    "                    #print(values)\n",
    "\n",
    "                    for value, index in zip(values, indexes):\n",
    "                        # print(value,index, type(value), type(index))\n",
    "                        # index = index.detach().cpu()\n",
    "\n",
    "                        new_mask = torch.clone(mask)\n",
    "                        new_mask[index] = 0\n",
    "                        new_res = copy.deepcopy(res)\n",
    "                        new_res.append(index)\n",
    "                        # print(\"nxt_queue:\", index, new_mask)\n",
    "                        # print(\"hcn size\", hcn[0].size())\n",
    "                        nxt_queue.append((value+score, (hcn[0][:,[index],:], hcn[1][:,[index],:]), new_mask, new_res))\n",
    "                j += 1\n",
    "            else:\n",
    "                for score, hcn, mask, res in queue:\n",
    "                    # print(\"x size:\", x.size(), x[:, [i], :].size())\n",
    "                    t_x, hcn = self.decoder(x[:, [i], :], hcn)\n",
    "                    nxt_queue.append((score, hcn, mask, res))    \n",
    "            nxt_queue.sort(key=lambda x:-x[0])\n",
    "            nxt_queue = nxt_queue[:k]\n",
    "            queue = nxt_queue\n",
    "            nxt_queue = []\n",
    "\n",
    "        return queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b534a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "def read_data(d):\n",
    "    return tuple([data.cuda() for data in d])\n",
    "\n",
    "model = BersonModel(model_name_or_path)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(\"./outputs/model_5000.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d4938cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_optimizer = list(model.named_parameters())\n",
    "# print([n for n,p in param_optimizer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b3a9093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 125292 acc_step: 1\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# Creating optimizer and lr schedulers\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "add = ['decoder, top']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay+add)],'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in add)], \"lr\":3e-5 , 'weight_decay': 0.01},\n",
    "]\n",
    "\n",
    "num_train_optimization_steps = int(epochs * len(train_loader) / accumulation_steps)\n",
    "print(\"steps:\",num_train_optimization_steps, \"acc_step:\", accumulation_steps)\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5,\n",
    "                  correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n",
    "                                            num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "scaler = torch.cuda.amp.GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc2a1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "f = open(\"./outputs/log.dat\", \"w+\")\n",
    "tbar = tqdm(train_loader,file=f)\n",
    "loss_list = []\n",
    "preds = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5fb62",
   "metadata": {},
   "source": [
    "## next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d91c506",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#if e <= 2:\n",
    "    #y_val, y_pred = validate(model, val_loader)\n",
    "    #val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "    #val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "    #y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "    #print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "    #continue\n",
    "#print(\"epoch:\", e)\n",
    "\n",
    "avg_loss = 0\n",
    "for idx, data in enumerate(tbar):\n",
    "    # print(type(data), type(data[0]), data[0].size())\n",
    "    # print(\"data[3].size()[1]: \",data[3].size()[1])\n",
    "    \n",
    "    data = read_data(data)\n",
    "    \n",
    "    #with torch.cuda.amp.autocast():\n",
    "    loss = model(*data)\n",
    "        # loss = criterion(pred, target)\n",
    "    scaler.scale(loss).backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "    if idx % accumulation_steps == 0 or idx == len(tbar) - 1:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        \n",
    "    loss_list.append(loss.detach().cpu().item())\n",
    "    if idx == 0:\n",
    "        continue\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "        avg_loss = np.round(np.mean(loss_list[-1000:]), 4)\n",
    "        # print(\"memory allocated:\",torch.cuda.memory_allocated(device=0) / (1024 * 1024))\n",
    "        print(\"avg_loss:\", avg_loss)\n",
    "    if idx % 5000 == 0:\n",
    "        torch.save(model.state_dict(), f\"./outputs/model_{idx}.bin\")\n",
    "\n",
    "    \n",
    "    # preds.append(pred.detach().cpu().numpy().ravel())\n",
    "    # labels.appendabs(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f90087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|██▋                                                                                                                                                                                                                                                                                                                                                                                 | 101/13964 [00:17<39:09,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs = read_data(data)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model.beam_search(*inputs)\n",
    "                #print(len(pred[0][-2]), pred[0][-1])\n",
    "                res = [t.detach().cpu().numpy().ravel()[0] for t in pred[0][-1]]\n",
    "            preds.append(res)\n",
    "            labels.append(np.arange(len(res)).ravel())\n",
    "            if idx > 100:\n",
    "                break\n",
    "    return labels, preds\n",
    "a, b = validate(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "362ffbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 10, 3, 4, 8, 2, 7, 5, 9, 11, 6] 19 132\n",
      "[0, 12, 13, 2, 20, 5, 18, 4, 8, 7, 15, 11, 14, 6, 1, 3, 19, 16, 17, 9, 10] 91 420\n",
      "[0, 1, 9, 3, 11, 10, 12, 6, 4, 7, 2, 8, 5] 34 156\n",
      "[8, 1, 5, 2, 4, 3, 7, 0, 9, 6] 20 90\n",
      "[8, 20, 0, 3, 5, 12, 17, 19, 14, 6, 1, 10, 4, 18, 7, 2, 13, 15, 9, 11, 16] 94 420\n",
      "[0] 0 0\n",
      "[5, 1, 6, 2, 4, 3, 0] 14 42\n",
      "[0] 0 0\n",
      "[1, 7, 2, 0, 3, 5, 6, 4, 9, 8] 11 90\n",
      "[15, 13, 1, 8, 10, 7, 11, 5, 9, 14, 6, 3, 0, 12, 2, 4] 80 240\n",
      "[1, 6, 0, 4, 5, 2, 3] 10 42\n",
      "[0, 11, 10, 6, 13, 8, 1, 3, 7, 9, 2, 5, 4, 12, 14] 47 210\n",
      "[6, 18, 3, 12, 15, 9, 2, 1, 10, 8, 7, 5, 13, 11, 14, 4, 16, 17, 0, 19] 82 380\n",
      "[9, 7, 3, 5, 10, 4, 8, 6, 0, 2, 1] 40 110\n",
      "[5, 7, 0, 6, 2, 1, 3, 4] 16 56\n",
      "[3, 1, 2, 4, 6, 0, 5] 8 42\n",
      "[10, 7, 0, 8, 2, 3, 6, 9, 5, 1, 11, 4] 34 132\n",
      "[29, 26, 24, 18, 27, 3, 16, 12, 23, 11, 20, 21, 8, 6, 19, 2, 7, 13, 14, 15, 30, 22, 25, 1, 4, 17, 5, 10, 28, 9, 0] 293 930\n",
      "[6, 28, 30, 3, 1, 16, 19, 11, 15, 14, 10, 32, 24, 22, 26, 31, 21, 20, 8, 18, 33, 27, 4, 5, 0, 9, 29, 12, 25, 7, 2, 23, 13, 17] 294 1122\n",
      "[6, 2, 7, 3, 5, 11, 1, 10, 12, 14, 0, 4, 9, 8, 13] 39 210\n",
      "[0, 1] 0 2\n",
      "[35, 16, 17, 19, 32, 6, 4, 9, 26, 11, 30, 27, 0, 10, 8, 33, 22, 21, 23, 18, 36, 3, 37, 5, 14, 29, 2, 7, 38, 15, 20, 1, 13, 31, 34, 24, 12, 25, 28] 350 1482\n",
      "[1, 7, 3, 0, 9, 8, 4, 6, 2, 5] 21 90\n",
      "[22, 9, 2, 3, 10, 7, 29, 5, 30, 33, 17, 31, 12, 23, 27, 32, 14, 13, 15, 11, 4, 20, 6, 24, 0, 18, 28, 1, 8, 26, 21, 25, 19, 16] 267 1122\n",
      "[9, 12, 1, 8, 5, 11, 13, 4, 10, 0, 7, 6, 2, 3] 59 182\n",
      "[9, 0, 2, 6, 14, 17, 3, 21, 22, 23, 16, 20, 4, 19, 15, 11, 1, 7, 18, 12, 8, 13, 10, 5] 138 552\n",
      "[0] 0 0\n",
      "[0, 2, 1, 3, 6, 7, 4, 5, 8] 5 72\n",
      "[0, 2, 1, 3, 5, 4] 2 30\n",
      "[5, 3, 0, 7, 10, 9, 4, 2, 11, 8, 1, 6] 31 132\n",
      "[3, 1, 0, 5, 7, 2, 4, 6] 9 56\n",
      "[14, 10, 24, 3, 18, 7, 6, 4, 0, 9, 19, 16, 22, 11, 8, 2, 17, 23, 5, 15, 12, 26, 20, 21, 1, 25, 13, 27] 146 756\n",
      "[0] 0 0\n",
      "[6, 0, 3, 4, 2, 10, 9, 5, 7, 8, 11, 1] 24 132\n",
      "[5, 7, 2, 3, 6, 1, 4, 0] 20 56\n",
      "[0, 1, 3, 16, 5, 9, 7, 6, 13, 12, 15, 11, 4, 14, 2, 8, 10] 51 272\n",
      "[11, 1, 9, 0, 2, 7, 8, 10, 3, 4, 5, 6] 32 132\n",
      "[0, 1, 3, 6, 5, 4, 2] 7 42\n",
      "[2, 1, 3, 0] 4 12\n",
      "[4, 21, 2, 19, 28, 26, 9, 1, 22, 16, 20, 24, 34, 12, 32, 5, 11, 7, 36, 18, 14, 33, 30, 3, 29, 25, 8, 27, 23, 31, 6, 35, 10, 0, 17, 15, 13] 323 1332\n",
      "[22, 15, 25, 5, 3, 7, 6, 45, 1, 9, 43, 12, 21, 28, 13, 46, 26, 41, 8, 32, 38, 18, 30, 27, 37, 20, 4, 17, 0, 16, 24, 2, 10, 14, 44, 11, 31, 47, 40, 36, 29, 42, 35, 34, 23, 33, 39, 19] 447 2256\n",
      "[0, 1] 0 2\n",
      "[9, 2, 10, 5, 3, 7, 6, 0, 4, 8, 1] 34 110\n",
      "[8, 3, 4, 2, 5, 6, 7, 1, 0] 23 72\n",
      "[0, 1, 3, 4, 2] 2 20\n",
      "[22, 25, 19, 3, 13, 24, 18, 21, 12, 14, 20, 4, 16, 9, 8, 2, 0, 17, 23, 7, 6, 26, 10, 11, 15, 5, 1] 229 702\n",
      "[28, 6, 12, 5, 27, 14, 10, 2, 25, 7, 26, 3, 1, 19, 16, 24, 20, 9, 23, 8, 17, 4, 15, 13, 11, 0, 18, 21, 22] 205 812\n",
      "[0, 1, 2] 0 6\n",
      "[0, 5, 16, 2, 14, 12, 6, 9, 3, 4, 11, 10, 8, 1, 15, 13, 7] 61 272\n",
      "[10, 22, 23, 2, 4, 21, 13, 24, 7, 3, 16, 0, 6, 8, 17, 14, 9, 5, 19, 1, 18, 25, 20, 11, 15, 12] 154 650\n",
      "[10, 0, 7, 5, 4, 2, 3, 1, 6, 8, 11, 9] 26 132\n",
      "[10, 0, 12, 13, 1, 4, 11, 2, 16, 8, 17, 14, 6, 7, 3, 15, 9, 5] 70 306\n",
      "[0, 3, 2, 4, 1, 5] 4 30\n",
      "[2, 1, 0, 5, 4, 3] 6 30\n",
      "[7, 1, 8, 10, 5, 0, 3, 9, 2, 4, 6] 29 110\n",
      "[50, 4, 48, 5, 2, 10, 27, 37, 3, 17, 14, 7, 51, 29, 32, 42, 1, 38, 19, 47, 21, 25, 43, 24, 34, 9, 8, 44, 22, 12, 36, 15, 26, 13, 30, 40, 39, 6, 33, 35, 18, 16, 11, 31, 49, 0, 41, 45, 20, 46, 28, 23] 596 2652\n",
      "[1, 4, 0, 2, 3] 4 20\n",
      "[7, 1, 3, 4, 6, 0, 8, 2, 5] 17 72\n",
      "[0, 7, 3, 4, 2, 6, 1, 8, 11, 13, 10, 12, 5, 9, 14] 25 210\n",
      "[1, 5, 4, 0, 2, 3] 8 30\n",
      "[11, 9, 14, 20, 12, 4, 18, 8, 6, 2, 0, 10, 13, 1, 3, 17, 7, 5, 15, 16, 19, 21] 103 462\n",
      "[0, 1, 4, 3, 2] 3 20\n",
      "[16, 21, 3, 10, 5, 13, 23, 8, 19, 7, 9, 4, 17, 2, 15, 1, 22, 20, 6, 18, 14, 11, 12, 0] 151 552\n",
      "[1, 0, 2, 4, 6, 7, 5, 3] 7 56\n",
      "[2, 1, 4, 5, 3, 0, 7, 6, 8] 9 72\n",
      "[12, 19, 0, 4, 9, 10, 6, 3, 7, 1, 5, 2, 8, 16, 13, 15, 18, 11, 17, 14] 68 380\n",
      "[3, 1, 2, 0] 5 12\n",
      "[8, 1, 2, 3, 7, 0, 5, 9, 6, 4] 19 90\n",
      "[2, 0, 3, 7, 6, 1, 5, 4] 11 56\n",
      "[7, 0, 3, 6, 4, 8, 5, 1, 2] 20 72\n",
      "[0, 4, 7, 5, 12, 9, 2, 1, 6, 11, 3, 8, 10] 29 156\n",
      "[4, 16, 18, 12, 2, 10, 15, 11, 13, 7, 8, 5, 23, 22, 19, 21, 9, 25, 14, 0, 17, 6, 1, 24, 3, 20] 155 650\n",
      "[8, 9, 2, 10, 11, 7, 4, 5, 6, 12, 0, 1, 3] 50 156\n",
      "[3, 0, 2, 13, 11, 22, 25, 6, 8, 10, 21, 18, 24, 15, 12, 4, 1, 23, 20, 5, 19, 17, 9, 14, 7, 16] 145 650\n",
      "[4, 8, 10, 1, 0, 2, 5, 3, 7, 9, 6] 23 110\n",
      "[2, 1, 9, 6, 0, 10, 8, 3, 5, 7, 4] 25 110\n",
      "[11, 1, 4, 10, 3, 9, 5, 0, 7, 6, 2, 8, 12] 36 156\n",
      "[0, 4, 2, 10, 8, 6, 5, 9, 3, 7, 1] 26 110\n",
      "[0, 5, 2, 1, 4, 6, 3] 7 42\n",
      "[5, 0, 7, 6, 9, 4, 8, 1, 3, 2] 26 90\n",
      "[0, 1, 2, 3] 0 12\n",
      "[2, 1, 0, 3, 4] 3 20\n",
      "[0, 2, 1, 3, 4] 1 20\n",
      "[8, 0, 3, 5, 1, 6, 4, 10, 16, 7, 15, 12, 14, 2, 13, 11, 9] 44 272\n",
      "[4, 1, 0, 8, 3, 6, 5, 2, 7] 14 72\n",
      "[0, 1, 2] 0 6\n",
      "[27, 30, 1, 18, 5, 35, 31, 7, 2, 26, 40, 11, 8, 0, 33, 38, 23, 34, 43, 42, 29, 45, 41, 4, 20, 44, 17, 39, 12, 6, 36, 15, 3, 28, 14, 46, 37, 32, 25, 16, 10, 21, 22, 13, 9, 19, 24] 540 2162\n",
      "[6, 3, 8, 1, 7, 2, 9, 10, 4, 0, 5] 28 110\n",
      "[0, 2, 1] 1 6\n",
      "[0, 2, 1] 1 6\n",
      "[6, 1, 4, 8, 5, 0, 3, 7, 9, 2] 21 90\n",
      "[0, 1] 0 2\n",
      "[3, 15, 18, 2, 21, 23, 28, 17, 5, 36, 29, 38, 24, 9, 26, 7, 33, 11, 25, 10, 31, 34, 4, 30, 19, 8, 12, 13, 16, 1, 37, 14, 27, 32, 22, 0, 20, 6, 35] 355 1482\n",
      "[2, 1, 0, 3, 5, 4] 4 30\n",
      "[15, 13, 10, 4, 0, 2, 6, 1, 5, 12, 17, 9, 14, 3, 19, 16, 8, 11, 7, 18, 20] 76 420\n",
      "[7, 6, 2, 11, 12, 4, 15, 0, 3, 13, 9, 1, 10, 14, 8, 5] 57 240\n",
      "[6, 5, 0, 9, 7, 3, 8, 2, 4, 1] 28 90\n",
      "[11, 6, 15, 13, 10, 7, 2, 8, 3, 4, 9, 5, 14, 12, 0, 1] 77 240\n",
      "[0, 9, 6, 1, 4, 5, 3, 8, 7, 2] 21 90\n",
      "[5, 14, 1, 0, 15, 3, 7, 8, 16, 9, 18, 17, 2, 4, 19, 13, 12, 6, 11, 10] 76 380\n",
      "[9, 29, 2, 21, 31, 7, 34, 19, 35, 37, 18, 32, 22, 39, 23, 16, 12, 1, 15, 14, 5, 20, 33, 30, 40, 4, 38, 8, 0, 6, 17, 3, 10, 11, 36, 25, 13, 28, 24, 27, 26] 422 1640\n",
      "[2, 0, 3, 1, 4] 3 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05785017957927141"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getInvCount(arr):\n",
    "    n = len(arr)\n",
    "    inv_count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if (arr[i] > arr[j]):\n",
    "                inv_count += 1\n",
    "  \n",
    "    return inv_count\n",
    "\n",
    "def kendall_tau(preds):\n",
    "    total_inversions, total_2max = 0, 0 \n",
    "    for pred in preds:\n",
    "        n = len(pred)\n",
    "        print(pred,count_inversions(pred), n * (n - 1))\n",
    "        total_inversions += count_inversions(pred)\n",
    "        total_2max += n * (n - 1) \n",
    "    return 1 - 4 * total_inversions / total_2max\n",
    "\n",
    "kendall_tau(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab09cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if e <= 2:\n",
    "    #y_val, y_pred = validate(model, val_loader)\n",
    "    #val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "    #val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "    #y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "    #print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "    #continue\n",
    "#print(\"epoch:\", e)\n",
    "\n",
    "avg_loss = 0\n",
    "for idx, data in enumerate(tbar):\n",
    "    # print(type(data), type(data[0]), data[0].size())\n",
    "    # print(\"data[3].size()[1]: \",data[3].size()[1])\n",
    "    \n",
    "    data = read_data(data)\n",
    "    \n",
    "    #with torch.cuda.amp.autocast():\n",
    "    loss = model(*data)\n",
    "        # loss = criterion(pred, target)\n",
    "    scaler.scale(loss).backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "    if idx % accumulation_steps == 0 or idx == len(tbar) - 1:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        \n",
    "    loss_list.append(loss.detach().cpu().item())\n",
    "    if idx == 0:\n",
    "        continue\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "        avg_loss = np.round(np.mean(loss_list[-1000:]), 4)\n",
    "        # print(\"memory allocated:\",torch.cuda.memory_allocated(device=0) / (1024 * 1024))\n",
    "        print(\"avg_loss:\", avg_loss)\n",
    "    if idx % 5000 == 0:\n",
    "        torch.save(model.state_dict(), f\"./outputs/model_{idx}.bin\")\n",
    "\n",
    "    \n",
    "    # preds.append(pred.detach().cpu().numpy().ravel())\n",
    "    # labels.appendabs(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.title('loss')\n",
    "plt.plot(loss_list, label='train')\n",
    "#plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21daaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b57b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "        pred = model(*inputs)\n",
    "        loss = criterion(pred, target)\n",
    "    scaler.scale(loss).backward()\n",
    "    if idx % args.accumulation_steps == 0 or idx == len(tbar) - 1:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "    if idx % 10000 == 0:\n",
    "        torch.save(model.state_dict(), f\"./outputs/model_{idx}.bin\")\n",
    "\n",
    "    loss_list.append(loss.detach().cpu().item())\n",
    "    preds.append(pred.detach().cpu().numpy().ravel())\n",
    "    labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "    avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "    tbar.set_description(f\"Epoch {e + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n",
    "\n",
    "\n",
    "\n",
    "y_val, y_pred = validate(model, val_loader)\n",
    "val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "torch.save(model.state_dict(), f\"./outputs/model_epoch_{e+1}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    tbar = tqdm(train_loader, file=sys.stdout)\n",
    "    loss_list = []\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    #if e <= 2:\n",
    "        #y_val, y_pred = validate(model, val_loader)\n",
    "        #val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "        #val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "        #y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "        #print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "        #continue\n",
    "    #print(\"epoch:\", e)\n",
    "\n",
    "    for idx, data in enumerate(tbar):\n",
    "        inputs = read_data(data)\n",
    "        target = 1\n",
    "\n",
    "        time.sleep(3)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(*inputs)\n",
    "            loss = criterion(pred, target)\n",
    "        scaler.scale(loss).backward()\n",
    "        if idx % args.accumulation_steps == 0 or idx == len(tbar) - 1:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "        if idx % 2000 == 0:\n",
    "            torch.save(model.state_dict(), f\"./outputs/model_{idx}.bin\")\n",
    "\n",
    "        loss_list.append(loss.detach().cpu().item())\n",
    "        preds.append(pred.detach().cpu().numpy().ravel())\n",
    "        labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "        avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "        tbar.set_description(f\"Epoch {e + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n",
    "\n",
    "    y_val, y_pred = validate(model, val_loader)\n",
    "    val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "    val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "    y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "    print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "    torch.save(model.state_dict(), f\"./outputs/model_epoch_{e+1}.bin\")\n",
    "\n",
    "return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"./outputs/model.bin\"))\n",
    "model, y_pred = train(model, train_loader, val_loader, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc['3a16a457']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46133176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697991d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77d894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e049489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "print(torch.cuda.memory_allocated(device=0) / (1024 * 1024))\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3333c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829c530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de554ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82953ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe16532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e595c7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
