{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb592be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 04:48:25.775721: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from dataset import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from model import *\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "from metrics import *\n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "\n",
    "import pynvml\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)   #gpu_id\n",
    "meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dfb88d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./outputs\"):\n",
    "    os.mkdir(\"./outputs\")\n",
    "data_dir = Path('..//input/')\n",
    "\n",
    "train_mark_path = './data/train_mark.csv'\n",
    "train_features_path = \"./data/train_fts.json\"\n",
    "val_mark_path = './data/val_mark.csv'\n",
    "val_features_path = './data/val_fts.json'\n",
    "val_path = \"./data/val.csv\"\n",
    "model_name_or_path =\"microsoft/codebert-base\"\n",
    "\n",
    "md_max_len = 512\n",
    "total_max_len = 64\n",
    "batch_size= 1\n",
    "accumulation_steps=1\n",
    "epochs=5 \n",
    "n_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34abc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_mark = pd.read_csv(train_mark_path).drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n",
    "train_fts = json.load(open(train_features_path))\n",
    "val_df_mark = pd.read_csv(val_mark_path).drop(\"parent_id\", axis=1).dropna().reset_index(drop=True)\n",
    "val_fts = json.load(open(val_features_path))\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "order_df = pd.read_csv(\"../input/train_orders.csv\").set_index(\"id\")\n",
    "#df_orders = pd.read_csv(\n",
    "#    data_dir / 'train_orders.csv',\n",
    "#    index_col='id',\n",
    "#    squeeze=True,\n",
    "#).str.split()\n",
    "\n",
    "order = pd.read_csv(\n",
    "    data_dir / 'train_orders.csv'\n",
    ")\n",
    "train_path = './data/train.csv'\n",
    "val_path = './data/val.csv'\n",
    "val_df = pd.read_csv(val_path)\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "full_df = pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9e039e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pct_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many he...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimpor...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>038b763d</td>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('igno...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2eefe0ef</td>\n",
       "      <td>code</td>\n",
       "      <td>matplotlib.rcParams.update({'font.size': 14})</td>\n",
       "      <td>6.0</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>0beab1cd</td>\n",
       "      <td>code</td>\n",
       "      <td>def evaluate_preds(train_true_values, train_pr...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   cell_id cell_type  \\\n",
       "0  00001756c60be8  1862f0a6      code   \n",
       "1  00001756c60be8  2a9e43d6      code   \n",
       "2  00001756c60be8  038b763d      code   \n",
       "3  00001756c60be8  2eefe0ef      code   \n",
       "4  00001756c60be8  0beab1cd      code   \n",
       "\n",
       "                                              source  rank ancestor_id  \\\n",
       "0  # This Python 3 environment comes with many he...   0.0    945aea18   \n",
       "1  import numpy as np\\nimport pandas as pd\\nimpor...   2.0    945aea18   \n",
       "2  import warnings\\nwarnings.filterwarnings('igno...   4.0    945aea18   \n",
       "3      matplotlib.rcParams.update({'font.size': 14})   6.0    945aea18   \n",
       "4  def evaluate_preds(train_true_values, train_pr...   8.0    945aea18   \n",
       "\n",
       "  parent_id  pct_rank  \n",
       "0       NaN  0.000000  \n",
       "1       NaN  0.034483  \n",
       "2       NaN  0.068966  \n",
       "3       NaN  0.103448  \n",
       "4       NaN  0.137931  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp = train_df_mark[train_df_mark['cell_type']=='markdown'].groupby(\"id\").count()['cell_id']\n",
    "# tmp.apply(lambda x: x**2).sum()/len(tmp) # = 539\n",
    "# tmp.mean() # = 15.56\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc51ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(df):\n",
    "    md_dict = dict(zip(df[\"cell_id\"].values, df['source'].values))\n",
    "    return md_dict\n",
    "\n",
    "md_dict = get_dict(full_df[full_df['cell_type']=='markdown'])\n",
    "cd_dict = get_dict(full_df[full_df['cell_type']=='code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893fb64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2165563, 4202444)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md_dict), len(cd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd17c047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1950114, 5740836, 215946, 629814)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_mark), len(train_df), len(val_df_mark), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad4b6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6 448eb224 2a9e43d6 7e2f170a 038b763d 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00015c83e2717b</td>\n",
       "      <td>2e94bd7a 3e99dee9 b5e286ea da4f7550 c417225b 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bdd4021779</td>\n",
       "      <td>3fdc37be 073782ca 8ea7263c 80543cd8 38310c80 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001daf4c2c76d</td>\n",
       "      <td>97266564 a898e555 86605076 76cc2642 ef279279 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>9ec225f0 18281c6c e3b6b115 4a044c54 365fe576 a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                         cell_order\n",
       "0  00001756c60be8  1862f0a6 448eb224 2a9e43d6 7e2f170a 038b763d 7...\n",
       "1  00015c83e2717b  2e94bd7a 3e99dee9 b5e286ea da4f7550 c417225b 5...\n",
       "2  0001bdd4021779  3fdc37be 073782ca 8ea7263c 80543cd8 38310c80 0...\n",
       "3  0001daf4c2c76d  97266564 a898e555 86605076 76cc2642 ef279279 d...\n",
       "4  0002115f48f982  9ec225f0 18281c6c e3b6b115 4a044c54 365fe576 a..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c482db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 2.86 µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_shuffle</th>\n",
       "      <th>permutation</th>\n",
       "      <th>md_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>[1862f0a6, 1862f0a6, 2a9e43d6, 448eb224, 038b7...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00015c83e2717b</td>\n",
       "      <td>[2e94bd7a, 3e99dee9, b5e286ea, da4f7550, c4172...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bdd4021779</td>\n",
       "      <td>[3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310...</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001daf4c2c76d</td>\n",
       "      <td>[97266564, a898e555, 86605076, 86605076, 76cc2...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>[9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                       cell_shuffle  \\\n",
       "0  00001756c60be8  [1862f0a6, 1862f0a6, 2a9e43d6, 448eb224, 038b7...   \n",
       "1  00015c83e2717b  [2e94bd7a, 3e99dee9, b5e286ea, da4f7550, c4172...   \n",
       "2  0001bdd4021779  [3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310...   \n",
       "3  0001daf4c2c76d  [97266564, a898e555, 86605076, 86605076, 76cc2...   \n",
       "4  0002115f48f982  [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe...   \n",
       "\n",
       "                                         permutation  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2                                             [0, 1]   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4                                                [0]   \n",
       "\n",
       "                                             md_mask  \n",
       "0  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, ...  \n",
       "1  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, ...  \n",
       "2            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]  \n",
       "3  [1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, ...  \n",
       "4                        [1, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "x = 1<<32\n",
    "seed = 42\n",
    "def transform(row):\n",
    "    \n",
    "    cell_ids = list(row[\"cell_order\"].split())\n",
    "    md_ids = []\n",
    "    cell_shuffle = []\n",
    "    md_mask = []\n",
    "    for cell_id in cell_ids:\n",
    "        if cell_id in md_dict:\n",
    "            cell_shuffle.append(0)\n",
    "            md_ids.append(cell_id)\n",
    "            md_mask.append(1)\n",
    "        else:\n",
    "            cell_shuffle.append(cell_id)\n",
    "            md_mask.append(0)\n",
    "    length = len(md_ids)\n",
    "    _hash = hash(row[\"cell_order\"])*seed % x\n",
    "    permutation = np.arange(length)\n",
    "    #permutation = np.random.RandomState(seed=_hash).permutation(length)\n",
    "    i = 0\n",
    "    for j in range(len(cell_shuffle)):\n",
    "        if cell_shuffle[j] == 0:\n",
    "            cell_shuffle[j] = cell_ids[permutation[i]]\n",
    "            i+=1\n",
    "    \n",
    "    return pd.Series([row.id, cell_shuffle, permutation, md_mask], index=['id', 'cell_shuffle', 'permutation', 'md_mask'])\n",
    "\n",
    "order = order.apply(transform, axis=1)\n",
    "order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722d9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ids =   train_df[\"id\"].unique()\n",
    "train_order = order[order[\"id\"].isin(tr_ids)]\n",
    "val_order  = order[~(order[\"id\"].isin(tr_ids))]\n",
    "train_df = train_df.set_index(\"cell_id\", drop=True)\n",
    "val_df = val_df.set_index(\"cell_id\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7854db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_order.head()\n",
    "# val_order.head()\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593912d7",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f1e87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bcf4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row = train_order.iloc[1]\n",
    "#cells = row.cell_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04fe10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[train_df.loc[cell_id].source for cell_id in cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb5ccef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tokenizer.batch_encode_plus(\n",
    "#            [train_df.loc[cell_id].source for cell_id in cells],\n",
    "#            add_special_tokens=True,\n",
    "#            max_length=total_max_len,\n",
    "#            padding=\"max_length\",\n",
    "#            # return_token_type_ids=True,\n",
    "#            truncation=True\n",
    "#        )\n",
    "#ids = torch.LongTensor(inputs['input_ids'])\n",
    "#mask = torch.LongTensor(inputs['attention_mask'])\n",
    "#md_mask = torch.LongTensor(row.md_mask)\n",
    "#permutation = torch.LongTensor(row.permutation)\n",
    "\n",
    "        \n",
    "#print(\"ids:\", ids.size())\n",
    "#print(\"mask:\", mask.size())\n",
    "#print(\"md_mask:\", md_mask.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e52b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkdownDataset(Dataset):\n",
    "    def __init__(self, order_df, df, model_name_or_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.order_df = order_df\n",
    "        self.df = df\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        self.fts = fts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.order_df.iloc[index]\n",
    "        cells = row.cell_shuffle\n",
    "\n",
    "        # print(\"index: \"+ str(index))\n",
    "\n",
    "        inputs = self.tokenizer.batch_encode_plus(\n",
    "            [self.df.loc[cell_id].source for cell_id in cells],\n",
    "            # None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.total_max_len,\n",
    "            padding=\"max_length\",\n",
    "            # return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        ids = torch.LongTensor(inputs['input_ids'])\n",
    "        mask = torch.LongTensor(inputs['attention_mask'])\n",
    "        md_mask = torch.LongTensor(row.md_mask)\n",
    "        permutation = torch.LongTensor(row.permutation)\n",
    "    \n",
    "        length = len(md_mask)\n",
    "        \n",
    "        #print(\"ids:\", ids.size())\n",
    "        #print(\"mask:\", mask.size())\n",
    "        #print(\"md_mask:\", md_mask.size())\n",
    "        #return torch.FloatTensor([length])\n",
    "        return ids, mask, permutation, md_mask, length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.order_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79675639",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MarkdownDataset(train_order, train_df, model_name_or_path=model_name_or_path, md_max_len=md_max_len,\n",
    "                           total_max_len=total_max_len, fts=train_fts)\n",
    "val_ds = MarkdownDataset(val_order, val_df, model_name_or_path=model_name_or_path, md_max_len=md_max_len,\n",
    "                         total_max_len=total_max_len, fts=val_fts)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=n_workers,\n",
    "                          pin_memory=False, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=n_workers,\n",
    "                        pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f80d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cpu()\n",
    "HIDDEN_SIZE = 768\n",
    "class BersonModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(BersonModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.decoder = nn.LSTM(input_size=HIDDEN_SIZE, hidden_size=HIDDEN_SIZE, num_layers=1, batch_first=True)\n",
    "        self.top = nn.Linear(HIDDEN_SIZE, 1)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.layernorm = nn.LayerNorm(2)\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "\n",
    "    def forward(self, ids, mask, order, md_mask, length):\n",
    "        \"\"\"\n",
    "        :param ids:\n",
    "        :param mask:\n",
    "        :param orders:\n",
    "        :param type: 0 for code, 1 for md\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ids = ids.squeeze(0) # [:8,:]\n",
    "        mask = mask.squeeze(0) # [:8,:]\n",
    "        order = order.squeeze(0)\n",
    "        md_mask = md_mask.squeeze(0)\n",
    "        # print(\"ids:\", ids.size())\n",
    "        #print(\"md_mask:\", md_mask.size())\n",
    "        #print(\"length:\", length)\n",
    "        \n",
    "        \n",
    "        #print(torch.cuda.memory_allocated(device=0) / (1024 * 1024))#0表示显卡号\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"size:\",ids.size()[0])\n",
    "        def get_batch():\n",
    "            q = 16\n",
    "            l = []\n",
    "            while q < length+16:\n",
    "                q_ids = ids[q-16:q, :]\n",
    "                q_mask = mask[q-16:q, :]\n",
    "                t = self.model(q_ids, q_mask)[1]\n",
    "                q += 16\n",
    "                l.append(t)\n",
    "            return torch.cat(l, 0)\n",
    "        \"\"\"\n",
    "        \n",
    "        def get_batch():\n",
    "            return self.model(ids, mask)[1].unsqueeze(0)\n",
    "        \n",
    "        if length > 96:\n",
    "            with torch.no_grad():\n",
    "                x = get_batch()\n",
    "        else:\n",
    "            x = get_batch()\n",
    "        del ids\n",
    "        del mask\n",
    "        \n",
    "        \n",
    "        # hn -> (Layer, batch, hiddenstate)\n",
    "        hn = torch.mean(x, 1).unsqueeze(1).cuda()\n",
    "        cn = torch.zeros_like(hn).cuda()\n",
    "        hcn = (hn, cn)\n",
    "        \n",
    "        md_len = len(order)\n",
    "        # print(\"hn:\", hn.size())\n",
    "        # x = self.model(ids, mask)[1]\n",
    "        # print(torch.cuda.memory_allocated(device=0) / (1024 * 1024))#0表示显卡号\n",
    "        \n",
    "        md_pos = [idx for idx, i in enumerate(md_mask) if i==1]\n",
    "        # print(\"md_pos:\", md_pos)\n",
    "        # print(\"md_mask:\", md_mask)\n",
    "        # print(\"order:\", order)\n",
    "        md_pool = torch.swapaxes(x[:, md_pos, :], 0, 1)\n",
    "        # print(\"md_num:\",md_len)\n",
    "        # print(\"md_pool:\", md_pool.size())\n",
    "        loss = 0\n",
    "        j, idx = 0, 0\n",
    "        for i in range(length):\n",
    "            if md_mask[i] == 1:\n",
    "                idx = order[j]\n",
    "                j += 1\n",
    "                # construct hcn for batch\n",
    "                hn, cn = hcn\n",
    "                hn = torch.tile(hn, (1, md_len, 1))\n",
    "                cn = torch.tile(cn, (1, md_len, 1))\n",
    "                t_hcn = (hn, cn)\n",
    "                \n",
    "                t_x, t_hcn = self.decoder(md_pool, t_hcn)\n",
    "                # t_x: (n, 1, h)\n",
    "                t_x = self.top(self.dropout(t_x))\n",
    "                # print(\"t_x:\", t_x.size(), \"  idx:\", idx)\n",
    "                output = self.softmax(t_x).squeeze(2).squeeze(1)\n",
    "                gt = torch.zeros_like(output)\n",
    "                gt[idx] = 1.\n",
    "                # print(\"output:\",output)\n",
    "                # print(\"gt:\", gt)\n",
    "                loss += self.loss(output, gt)\n",
    "                del t_hcn\n",
    "            # print(\"test:\", x[:, [i], :].size())\n",
    "            output, hcn = self.decoder(x[:, [i], :], hcn)\n",
    "        \n",
    "                \n",
    "        \n",
    "        ## concat\n",
    "        loss /= md_len\n",
    "        # print(\"loss:\", loss)\n",
    "\n",
    "        # lstm\n",
    "        #hn = \n",
    "        #hcn = \n",
    "        #for t in range():\n",
    "        #    output, hcn = self.decoder(x, hcn) # hcn = (hidden_state, cell_state)\n",
    "        # loss\n",
    "        # loss = 1\n",
    "\n",
    "        ## sentence order\n",
    "\n",
    "        ## coherence\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b534a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def read_data(d):\n",
    "    return tuple([data.cuda() for data in d])\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "\n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs = read_data(data)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs):\n",
    "    np.random.seed(0)\n",
    "    # Creating optimizer and lr schedulers\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    num_train_optimization_steps = int(epochs * len(train_loader) / accumulation_steps)\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5,\n",
    "                      correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n",
    "                                                num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n",
    "\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        tbar = tqdm(train_loader, file=sys.stdout)\n",
    "        loss_list = []\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        #if e <= 2:\n",
    "            #y_val, y_pred = validate(model, val_loader)\n",
    "            #val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "            #val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "            #y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "            #print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "            #continue\n",
    "        #print(\"epoch:\", e)\n",
    "\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs = read_data(data)\n",
    "            target = 1\n",
    "            \n",
    "            time.sleep(3)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(*inputs)\n",
    "                loss = criterion(pred, target)\n",
    "            scaler.scale(loss).backward()\n",
    "            if idx % args.accumulation_steps == 0 or idx == len(tbar) - 1:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "\n",
    "            if idx % 10000 == 0:\n",
    "                torch.save(model.state_dict(), f\"./outputs/model_{idx}.bin\")\n",
    "\n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "            avg_loss = np.round(np.mean(loss_list), 4)\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "            tbar.set_description(f\"Epoch {e + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n",
    "\n",
    "        y_val, y_pred = validate(model, val_loader)\n",
    "        val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "        val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "        y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "        print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "        torch.save(model.state_dict(), f\"./outputs/model_epoch_{e+1}.bin\")\n",
    "\n",
    "    return model, y_pred\n",
    "\n",
    "model = BersonModel(model_name_or_path)\n",
    "model = model.cuda()\n",
    "# model.load_state_dict(torch.load(\"./outputs/model_10000.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b3a9093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 626460 acc: 1\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# Creating optimizer and lr schedulers\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "num_train_optimization_steps = int(epochs * len(train_loader) / accumulation_steps)\n",
    "print(\"steps:\",num_train_optimization_steps, \"acc_step:\", accumulation_steps)\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5,\n",
    "                  correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n",
    "                                            num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "scaler = torch.cuda.amp.GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77caa223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                                                                                                                                                                             | 0/125292 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.7626953125\n",
      "avg_loss: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                                                                                                                                                                                                                              | 103/125292 [01:59<106:51:27,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1988.10888671875\n",
      "avg_loss: 0.2793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                                                                                                                                                                                                                                                                               | 202/125292 [03:13<30:32:35,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.7353515625\n",
      "avg_loss: 0.2936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▉                                                                                                                                                                                                                                                                                                                                                                               | 302/125292 [04:43<18:33:52,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.7373046875\n",
      "avg_loss: 0.3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|█▏                                                                                                                                                                                                                                                                                                                                                                             | 401/125292 [06:24<137:40:00,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.7705078125\n",
      "avg_loss: 0.3064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|█▍                                                                                                                                                                                                                                                                                                                                                                              | 502/125292 [07:44<32:56:41,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.79443359375\n",
      "avg_loss: 0.3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|█▊                                                                                                                                                                                                                                                                                                                                                                              | 602/125292 [09:31<28:13:58,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.7431640625\n",
      "avg_loss: 0.3115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██                                                                                                                                                                                                                                                                                                                                                                              | 702/125292 [11:19<20:36:16,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.7216796875\n",
      "avg_loss: 0.3068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▎                                                                                                                                                                                                                                                                                                                                                                             | 801/125292 [12:46<22:30:27,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.75390625\n",
      "avg_loss: 0.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▋                                                                                                                                                                                                                                                                                                                                                                             | 902/125292 [14:37<40:56:17,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.78076171875\n",
      "avg_loss: 0.3068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▉                                                                                                                                                                                                                                                                                                                                                                            | 1001/125292 [16:00<23:51:28,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.763671875\n",
      "avg_loss: 0.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|███▏                                                                                                                                                                                                                                                                                                                                                                           | 1103/125292 [18:02<17:51:09,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.74609375\n",
      "avg_loss: 0.3088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|███▌                                                                                                                                                                                                                                                                                                                                                                           | 1202/125292 [19:53<36:39:51,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.8603515625\n",
      "avg_loss: 0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|███▊                                                                                                                                                                                                                                                                                                                                                                           | 1303/125292 [21:41<16:49:11,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.7392578125\n",
      "avg_loss: 0.3041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|████                                                                                                                                                                                                                                                                                                                                                                           | 1401/125292 [23:08<22:14:59,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory allocated: 1987.732421875\n",
      "avg_loss: 0.3044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|████▏                                                                                                                                                                                                                                                                                                                                                                          | 1433/125292 [23:44<34:12:24,  1.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# loss = criterion(pred, target)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(tbar) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     28\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n",
      "File \u001b[0;32m~/anaconda3/envs/VIT/lib/python3.8/site-packages/torch/tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    238\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    239\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    244\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 245\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/VIT/lib/python3.8/site-packages/torch/autograd/__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 145\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "tbar = tqdm(train_loader)\n",
    "loss_list = []\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "#if e <= 2:\n",
    "    #y_val, y_pred = validate(model, val_loader)\n",
    "    #val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "    #val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "    #y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "    #print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "    #continue\n",
    "#print(\"epoch:\", e)\n",
    "\n",
    "avg_loss = 0\n",
    "for idx, data in enumerate(tbar):\n",
    "    # print(type(data), type(data[0]), data[0].size())\n",
    "    # print(\"data[3].size()[1]: \",data[3].size()[1])\n",
    "        \n",
    "    data = read_data(data)\n",
    "    \n",
    "    #with torch.cuda.amp.autocast():\n",
    "    loss = model(*data)\n",
    "        # loss = criterion(pred, target)\n",
    "    scaler.scale(loss).backward()\n",
    "    if idx % accumulation_steps == 0 or idx == len(tbar) - 1:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "        print(\"memory allocated:\",torch.cuda.memory_allocated(device=0) / (1024 * 1024))\n",
    "        print(\"avg_loss:\", avg_loss)\n",
    "    if idx % 5000 == 0:\n",
    "        torch.save(model.state_dict(), f\"./outputs/model_{idx}.bin\")\n",
    "\n",
    "    loss_list.append(loss.detach().cpu().item())\n",
    "    # preds.append(pred.detach().cpu().numpy().ravel())\n",
    "    # labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "    avg_loss = np.round(np.mean(loss_list), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5fb62",
   "metadata": {},
   "source": [
    "## next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a7ab77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde74966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a628b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49aa3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed31a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "        pred = model(*inputs)\n",
    "        loss = criterion(pred, target)\n",
    "    scaler.scale(loss).backward()\n",
    "    if idx % args.accumulation_steps == 0 or idx == len(tbar) - 1:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "\n",
    "    if idx % 10000 == 0:\n",
    "        torch.save(model.state_dict(), f\"./outputs/model_{idx}.bin\")\n",
    "\n",
    "    loss_list.append(loss.detach().cpu().item())\n",
    "    preds.append(pred.detach().cpu().numpy().ravel())\n",
    "    labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "    avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "    tbar.set_description(f\"Epoch {e + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n",
    "\n",
    "\n",
    "\n",
    "y_val, y_pred = validate(model, val_loader)\n",
    "val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "torch.save(model.state_dict(), f\"./outputs/model_epoch_{e+1}.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    tbar = tqdm(train_loader, file=sys.stdout)\n",
    "    loss_list = []\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    #if e <= 2:\n",
    "        #y_val, y_pred = validate(model, val_loader)\n",
    "        #val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "        #val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "        #y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "        #print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "        #continue\n",
    "    #print(\"epoch:\", e)\n",
    "\n",
    "    for idx, data in enumerate(tbar):\n",
    "        inputs = read_data(data)\n",
    "        target = 1\n",
    "\n",
    "        time.sleep(3)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(*inputs)\n",
    "            loss = criterion(pred, target)\n",
    "        scaler.scale(loss).backward()\n",
    "        if idx % args.accumulation_steps == 0 or idx == len(tbar) - 1:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "        if idx % 10000 == 0:\n",
    "            torch.save(model.state_dict(), f\"./outputs/model_{idx}.bin\")\n",
    "\n",
    "        loss_list.append(loss.detach().cpu().item())\n",
    "        preds.append(pred.detach().cpu().numpy().ravel())\n",
    "        labels.append(target.detach().cpu().numpy().ravel())\n",
    "\n",
    "        avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "        tbar.set_description(f\"Epoch {e + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n",
    "\n",
    "    y_val, y_pred = validate(model, val_loader)\n",
    "    val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "    val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
    "    y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
    "    print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
    "    torch.save(model.state_dict(), f\"./outputs/model_epoch_{e+1}.bin\")\n",
    "\n",
    "return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"./outputs/model.bin\"))\n",
    "model, y_pred = train(model, train_loader, val_loader, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc['3a16a457']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46133176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697991d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77d894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e049489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc0a8f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2053.2802734375\n",
      "0.0002880096435546875\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "print(torch.cuda.memory_allocated(device=0) / (1024 * 1024))\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3333c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829c530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de554ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82953ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe16532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e595c7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
