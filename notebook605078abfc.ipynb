{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ce69c6",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-05-09T23:29:49.585748Z",
     "iopub.status.busy": "2023-05-09T23:29:49.585077Z",
     "iopub.status.idle": "2023-05-09T23:30:21.383517Z",
     "shell.execute_reply": "2023-05-09T23:30:21.382145Z"
    },
    "papermill": {
     "duration": 31.80928,
     "end_time": "2023-05-09T23:30:21.386117",
     "exception": false,
     "start_time": "2023-05-09T23:29:49.576837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/nnaudio031/nnAudio-0.3.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from nnAudio==0.3.1) (1.9.3)\r\n",
      "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from scipy->nnAudio==0.3.1) (1.23.5)\r\n",
      "Installing collected packages: nnAudio\r\n",
      "Successfully installed nnAudio-0.3.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## setup\n",
    "!pip install ../input/nnaudio031/nnAudio-0.3.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37de8d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:21.400802Z",
     "iopub.status.busy": "2023-05-09T23:30:21.400378Z",
     "iopub.status.idle": "2023-05-09T23:30:21.404937Z",
     "shell.execute_reply": "2023-05-09T23:30:21.404206Z"
    },
    "papermill": {
     "duration": 0.014301,
     "end_time": "2023-05-09T23:30:21.407033",
     "exception": false,
     "start_time": "2023-05-09T23:30:21.392732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls /kaggle/input/blef0503/\n",
    "# !ls /kaggle/input/ef-v0/\n",
    "# !ls /kaggle/input/birds-inference-pip-wheels/*\n",
    "# !pip freeze|grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00189e1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:21.421284Z",
     "iopub.status.busy": "2023-05-09T23:30:21.420716Z",
     "iopub.status.idle": "2023-05-09T23:30:21.425478Z",
     "shell.execute_reply": "2023-05-09T23:30:21.424683Z"
    },
    "papermill": {
     "duration": 0.014152,
     "end_time": "2023-05-09T23:30:21.427411",
     "exception": false,
     "start_time": "2023-05-09T23:30:21.413259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## https://github.com/Selimonder/birdclef2022/\n",
    "import os, sys, glob, math\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "github_folder = \"/kaggle/input/blef0508v3\"\n",
    "sys.path.append(github_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e893ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:21.441560Z",
     "iopub.status.busy": "2023-05-09T23:30:21.440947Z",
     "iopub.status.idle": "2023-05-09T23:30:28.839089Z",
     "shell.execute_reply": "2023-05-09T23:30:28.837811Z"
    },
    "papermill": {
     "duration": 7.408263,
     "end_time": "2023-05-09T23:30:28.841911",
     "exception": false,
     "start_time": "2023-05-09T23:30:21.433648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import librosa\n",
    "import argparse, warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import zoo\n",
    "from training.config import load_config\n",
    "from training.datasets import BirdDatasetOOF\n",
    "\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2389a1e",
   "metadata": {
    "papermill": {
     "duration": 0.006283,
     "end_time": "2023-05-09T23:30:28.855053",
     "exception": false,
     "start_time": "2023-05-09T23:30:28.848770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f212f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:28.869730Z",
     "iopub.status.busy": "2023-05-09T23:30:28.869339Z",
     "iopub.status.idle": "2023-05-09T23:30:29.470296Z",
     "shell.execute_reply": "2023-05-09T23:30:29.469281Z"
    },
    "papermill": {
     "duration": 0.610889,
     "end_time": "2023-05-09T23:30:29.472431",
     "exception": false,
     "start_time": "2023-05-09T23:30:28.861542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False <class 'bool'>\n",
      "/kaggle/input/e40-ef0/ef_v0TimmClassifier_v3_tf_efficientnet_b0_0_lb\n",
      "initing CLS features model 15 duration...\n",
      "{'in_chans': 1, 'drop_path_rate': 0.2, 'drop_rate': 0.5}\n",
      "=> loading checkpoint '/kaggle/input/e40-ef0/ef_v0TimmClassifier_v3_tf_efficientnet_b0_0_lb''\n",
      "epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(conf_path: str, weights_path: str, prefix: str, suffix: str, fold: int, to_device: bool = True):\n",
    "    conf = load_config(conf_path)\n",
    "    conf['encoder_params']['pretrained'] = False\n",
    "    print(conf['encoder_params']['pretrained'], type(conf['encoder_params']['pretrained']))\n",
    "    \n",
    "    snapshot_name = \"{}{}_{}_{}_{}\".format(prefix, conf[\"network\"], conf[\"encoder_params\"][\"encoder\"], fold, suffix)\n",
    "    weights_path = os.path.join(weights_path, snapshot_name)\n",
    "    print(weights_path)\n",
    "    \n",
    "    model = zoo.__dict__[conf[\"network\"]](**conf[\"encoder_params\"])\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    print(\"=> loading checkpoint '{}''\".format(weights_path))\n",
    "    checkpoint = torch.load(weights_path, map_location=\"cpu\")\n",
    "    print(\"epoch\", checkpoint[\"epoch\"])\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model.eval()\n",
    "    if to_device: model.cuda()\n",
    "    return model\n",
    "\n",
    "models = []\n",
    "\n",
    "## best only for now\n",
    "suffixes = [\"lb\"]#, \"f1_score\" \"last\"]\n",
    "folds    = 5\n",
    "\n",
    "# 16min rank82  cls_ef_v0.json weights_path = f\"/kaggle/input/cls-ef-v0\", prefix = \"ef_v0\",\n",
    "# rank90  cls_ef_v0.json weights_path = f\"/kaggle/input/ef-v0-pretrain\", prefix = \"ef_v0_\",\n",
    "\n",
    "# 44 min0.79 240 conf_path    = f\"{github_folder}/configs/cls_nf0_v5.json\", weights_path = f\"/kaggle/input/nf0-v5\", prefix       = \"nf0_v5_\",\n",
    "\n",
    "# \n",
    "#  cls_nf0_v5.json\",weights_path = nfnet-baseline-bs16/nfnet-baseline-bs16, prefix= \"nf0_v5_\",\n",
    "\n",
    "\n",
    "# 0.78\n",
    "# f\"{github_folder}/configs/cls_nf0_v5.json\",\n",
    "# weights_path = f\"/kaggle/input/nfnet-baseline-bs16/nfnet-baseline-bs16\",\n",
    "# prefix       = \"nf0_v5_\",\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "for i in [0]:\n",
    "    for sx in suffixes:\n",
    "        try:\n",
    "            model = load_model(conf_path    = f\"{github_folder}/configs/cls_ef_v0.json\",\n",
    "                               weights_path = f\"/kaggle/input/e40-ef0\",\n",
    "                               prefix       = \"ef_v0\",\n",
    "                               suffix       = sx,\n",
    "                               fold         = i,\n",
    "                               to_device    = False,)\n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"model not found\", e)\n",
    "\n",
    "len(models)\n",
    "#models = [models[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa74801d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:29.487936Z",
     "iopub.status.busy": "2023-05-09T23:30:29.487537Z",
     "iopub.status.idle": "2023-05-09T23:30:29.497122Z",
     "shell.execute_reply": "2023-05-09T23:30:29.495879Z"
    },
    "papermill": {
     "duration": 0.020218,
     "end_time": "2023-05-09T23:30:29.499617",
     "exception": false,
     "start_time": "2023-05-09T23:30:29.479399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3593"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(models[0])//1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c6196",
   "metadata": {
    "papermill": {
     "duration": 0.006546,
     "end_time": "2023-05-09T23:30:29.513114",
     "exception": false,
     "start_time": "2023-05-09T23:30:29.506568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b79342e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:29.529113Z",
     "iopub.status.busy": "2023-05-09T23:30:29.528422Z",
     "iopub.status.idle": "2023-05-09T23:30:29.533921Z",
     "shell.execute_reply": "2023-05-09T23:30:29.532797Z"
    },
    "papermill": {
     "duration": 0.016423,
     "end_time": "2023-05-09T23:30:29.536171",
     "exception": false,
     "start_time": "2023-05-09T23:30:29.519748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLASSES = \"abethr1 abhori1 abythr1 afbfly1 afdfly1 afecuc1 affeag1 afgfly1 afghor1 afmdov1 afpfly1 afpkin1 afpwag1 afrgos1 afrgrp1 afrjac1 afrthr1 amesun2 augbuz1 bagwea1 barswa bawhor2 bawman1 bcbeat1 beasun2 bkctch1 bkfruw1 blacra1 blacuc1 blakit1 blaplo1 blbpuf2 blcapa2 blfbus1 blhgon1 blhher1 blksaw1 blnmou1 blnwea1 bltapa1 bltbar1 bltori1 blwlap1 brcale1 brcsta1 brctch1 brcwea1 brican1 brobab1 broman1 brosun1 brrwhe3 brtcha1 brubru1 brwwar1 bswdov1 btweye2 bubwar2 butapa1 cabgre1 carcha1 carwoo1 categr ccbeat1 chespa1 chewea1 chibat1 chtapa3 chucis1 cibwar1 cohmar1 colsun2 combul2 combuz1 comsan crefra2 crheag1 crohor1 darbar1 darter3 didcuc1 dotbar1 dutdov1 easmog1 eaywag1 edcsun3 egygoo equaka1 eswdov1 eubeat1 fatrav1 fatwid1 fislov1 fotdro5 gabgos2 gargan gbesta1 gnbcam2 gnhsun1 gobbun1 gobsta5 gobwea1 golher1 grbcam1 grccra1 grecor greegr grewoo2 grwpyt1 gryapa1 grywrw1 gybfis1 gycwar3 gyhbus1 gyhkin1 gyhneg1 gyhspa1 gytbar1 hadibi1 hamerk1 hartur1 helgui hipbab1 hoopoe huncis1 hunsun2 joygre1 kerspa2 klacuc1 kvbsun1 laudov1 lawgol lesmaw1 lessts1 libeat1 litegr litswi1 litwea1 loceag1 lotcor1 lotlap1 luebus1 mabeat1 macshr1 malkin1 marsto1 marsun2 mcptit1 meypar1 moccha1 mouwag1 ndcsun2 nobfly1 norbro1 norcro1 norfis1 norpuf1 nubwoo1 pabspa1 palfly2 palpri1 piecro1 piekin1 pitwhy purgre2 pygbat1 quailf1 ratcis1 raybar1 rbsrob1 rebfir2 rebhor1 reboxp1 reccor reccuc1 reedov1 refbar2 refcro1 reftin1 refwar2 rehblu1 rehwea1 reisee2 rerswa1 rewsta1 rindov rocmar2 rostur1 ruegls1 rufcha2 sacibi2 sccsun2 scrcha1 scthon1 shesta1 sichor1 sincis1 slbgre1 slcbou1 sltnig1 sobfly1 somgre1 somtit4 soucit1 soufis1 spemou2 spepig1 spewea1 spfbar1 spfwea1 spmthr1 spwlap1 squher1 strher strsee1 stusta1 subbus1 supsta1 tacsun1 tafpri1 tamdov1 thrnig1 trobou1 varsun2 vibsta2 vilwea1 vimwea1 walsta1 wbgbir1 wbrcha2 wbswea1 wfbeat1 whbcan1 whbcou1 whbcro2 whbtit5 whbwea1 whbwhe3 whcpri2 whctur2 wheslf1 whhsaw1 whihel1 whrshr1 witswa1 wlwwar wookin1 woosan wtbeat1 yebapa1 yebbar1 yebduc1 yebere1 yebgre1 yebsto1 yeccan1 yefcan yelbis1 yenspu1 yertin1 yesbar1 yespet1 yetgre1 yewgre1\".split()\n",
    "N_CLASS = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae176099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:29.552530Z",
     "iopub.status.busy": "2023-05-09T23:30:29.551313Z",
     "iopub.status.idle": "2023-05-09T23:30:29.561154Z",
     "shell.execute_reply": "2023-05-09T23:30:29.560304Z"
    },
    "papermill": {
     "duration": 0.019772,
     "end_time": "2023-05-09T23:30:29.563155",
     "exception": false,
     "start_time": "2023-05-09T23:30:29.543383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "frame_length = 5\n",
    "infer_frame_length = 5\n",
    "sample_rate  = 32000\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 df: pd.DataFrame, \n",
    "                 sample_rate:int,\n",
    "                 frame_length:int,\n",
    "                 waveform\n",
    "                ):\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        self.frame_length = frame_length\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "        self.waveform = waveform\n",
    "        self.n_parts = math.ceil(len(waveform) / int(infer_frame_length * sample_rate))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_parts\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.df.loc[idx, :]\n",
    "        row_id = sample.row_id\n",
    "        sample_rate = self.sample_rate\n",
    "        frame_length = self.frame_length\n",
    "\n",
    "        end_seconds = int(sample.seconds)\n",
    "        start_seconds = int(end_seconds - 5)\n",
    "        \n",
    "        y = self.waveform[sample_rate * start_seconds : sample_rate * end_seconds].astype(np.float32)\n",
    "        \n",
    "        wav_tensor = torch.from_numpy(y)\n",
    "        if len(wav_tensor) == frame_length * sample_rate:\n",
    "            pass\n",
    "        elif len(wav_tensor) < frame_length * sample_rate:\n",
    "            wav_tensor = torch.nn.functional.pad(wav_tensor, (0, (frame_length * sample_rate) - len(wav_tensor)))\n",
    "        elif len(wav_tensor) > frame_length * sample_rate:\n",
    "            wav_tensor = wav_tensor[:(frame_length * sample_rate)]\n",
    "        \n",
    "        # add channel\n",
    "        wav_tensor = wav_tensor.unsqueeze(0)\n",
    "        \n",
    "        return {\n",
    "            \"wav_tensors\": wav_tensor,\n",
    "            \"row_id\": row_id,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b99593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:29.579096Z",
     "iopub.status.busy": "2023-05-09T23:30:29.578394Z",
     "iopub.status.idle": "2023-05-09T23:30:29.593979Z",
     "shell.execute_reply": "2023-05-09T23:30:29.592833Z"
    },
    "papermill": {
     "duration": 0.026566,
     "end_time": "2023-05-09T23:30:29.596726",
     "exception": false,
     "start_time": "2023-05-09T23:30:29.570160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_audios = list(Path(\"../input/birdclef-2023/test_soundscapes/\").glob(\"*.ogg\")) \n",
    "seconds = [i for i in range(5, 605, 5)]\n",
    "\n",
    "class CFG:\n",
    "    batch_size=4\n",
    "    num_workers=4\n",
    "    \n",
    "config = CFG()\n",
    "\n",
    "def prediction_for_clip(\n",
    "    audio_path\n",
    "):\n",
    "    \n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    # inference\n",
    "    prediction_dict = {}\n",
    "    \n",
    "    clip, _ = librosa.load(audio_path, sr=sample_rate, mono=True)\n",
    "    name_ = \"_\".join(audio_path.name.split(\".\")[:-1])\n",
    "    row_ids = [name_+f\"_{second}\" for second in seconds]\n",
    "\n",
    "    test_df = pd.DataFrame({\n",
    "        \"row_id\": row_ids,\n",
    "        \"seconds\": seconds\n",
    "    })\n",
    "    \n",
    "        \n",
    "    dataset = TestDataset(\n",
    "        df=test_df, \n",
    "        sample_rate=sample_rate,\n",
    "        frame_length=frame_length,\n",
    "        waveform=clip\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config.batch_size, \n",
    "        num_workers=config.num_workers,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    for data in loader:\n",
    "\n",
    "        row_ids = data['row_id']\n",
    "\n",
    "        for row_id in row_ids:\n",
    "            if row_id not in prediction_dict:\n",
    "                prediction_dict[str(row_id)] = []\n",
    "\n",
    "        probas = []\n",
    "\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # print(type(data[\"wav_tensors\"]))\n",
    "                # print(data[\"wav_tensors\"].size())\n",
    "                # output = model(data[\"wav_tensors\"])\n",
    "                output = model(data[\"wav_tensors\"], is_test=True)[\"logit\"].sigmoid()\n",
    "#                     \n",
    "            for row_id_idx, row_id in enumerate(row_ids):\n",
    "                prediction_dict[str(row_id)].append(output[[row_id_idx]].numpy().reshape(-1))\n",
    "                                                        \n",
    "    for row_id in list(prediction_dict.keys()):\n",
    "                \n",
    "        logits = np.array(prediction_dict[row_id]).mean(0)\n",
    "        prediction_dict[row_id] = {}\n",
    "        for label in range(N_CLASS):\n",
    "            prediction_dict[row_id][CLASSES[label]] = logits[label]\n",
    "\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79ede899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:29.612377Z",
     "iopub.status.busy": "2023-05-09T23:30:29.611977Z",
     "iopub.status.idle": "2023-05-09T23:30:29.616485Z",
     "shell.execute_reply": "2023-05-09T23:30:29.615426Z"
    },
    "papermill": {
     "duration": 0.015005,
     "end_time": "2023-05-09T23:30:29.618570",
     "exception": false,
     "start_time": "2023-05-09T23:30:29.603565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# start = time.time()\n",
    "# dicts = []\n",
    "# for audio_path in all_audios:\n",
    "#     dicts.append(prediction_for_clip(audio_path))\n",
    "# print(f\"Regular for loop costs {time.time()-start} for processing {len(all_audios)} audios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fed4d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:29.633966Z",
     "iopub.status.busy": "2023-05-09T23:30:29.633580Z",
     "iopub.status.idle": "2023-05-09T23:30:48.923683Z",
     "shell.execute_reply": "2023-05-09T23:30:48.922162Z"
    },
    "papermill": {
     "duration": 19.300536,
     "end_time": "2023-05-09T23:30:48.926100",
     "exception": false,
     "start_time": "2023-05-09T23:30:29.625564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With concurrent ThreadPoolExecutor, time cost reduced to 19.3 for processing 1 audios\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "start = time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    dicts = list(executor.map(prediction_for_clip, all_audios))\n",
    "print(f\"With concurrent ThreadPoolExecutor, time cost reduced to {time.time()-start:.1f} for processing {len(all_audios)} audios\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73cd3386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:48.942703Z",
     "iopub.status.busy": "2023-05-09T23:30:48.942081Z",
     "iopub.status.idle": "2023-05-09T23:30:49.073880Z",
     "shell.execute_reply": "2023-05-09T23:30:49.072634Z"
    },
    "papermill": {
     "duration": 0.142872,
     "end_time": "2023-05-09T23:30:49.076091",
     "exception": false,
     "start_time": "2023-05-09T23:30:48.933219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total rows : 120\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>abethr1</th>\n",
       "      <th>abhori1</th>\n",
       "      <th>abythr1</th>\n",
       "      <th>afbfly1</th>\n",
       "      <th>afdfly1</th>\n",
       "      <th>afecuc1</th>\n",
       "      <th>affeag1</th>\n",
       "      <th>afgfly1</th>\n",
       "      <th>afghor1</th>\n",
       "      <th>...</th>\n",
       "      <th>yebsto1</th>\n",
       "      <th>yeccan1</th>\n",
       "      <th>yefcan</th>\n",
       "      <th>yelbis1</th>\n",
       "      <th>yenspu1</th>\n",
       "      <th>yertin1</th>\n",
       "      <th>yesbar1</th>\n",
       "      <th>yespet1</th>\n",
       "      <th>yetgre1</th>\n",
       "      <th>yewgre1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_29201_5</td>\n",
       "      <td>0.024468</td>\n",
       "      <td>0.016309</td>\n",
       "      <td>0.128915</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.025380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_29201_10</td>\n",
       "      <td>0.018099</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.049784</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.020096</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.013634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>0.034829</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.071354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_29201_15</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.023540</td>\n",
       "      <td>0.034404</td>\n",
       "      <td>0.018561</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.039497</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>0.012738</td>\n",
       "      <td>0.037714</td>\n",
       "      <td>0.010992</td>\n",
       "      <td>0.013150</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.035175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_29201_20</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.018199</td>\n",
       "      <td>0.011695</td>\n",
       "      <td>0.010560</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>0.017739</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.027206</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.009040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_29201_25</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>0.013096</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>0.012779</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.006497</td>\n",
       "      <td>0.009672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                row_id   abethr1   abhori1   abythr1   afbfly1   afdfly1  \\\n",
       "0   soundscape_29201_5  0.024468  0.016309  0.128915  0.002223  0.002169   \n",
       "1  soundscape_29201_10  0.018099  0.153154  0.006084  0.049784  0.009905   \n",
       "2  soundscape_29201_15  0.020476  0.023540  0.034404  0.018561  0.007867   \n",
       "3  soundscape_29201_20  0.004694  0.018199  0.011695  0.010560  0.013242   \n",
       "4  soundscape_29201_25  0.002801  0.015591  0.010036  0.014981  0.013096   \n",
       "\n",
       "    afecuc1   affeag1   afgfly1   afghor1  ...   yebsto1   yeccan1    yefcan  \\\n",
       "0  0.008502  0.007558  0.004082  0.025380  ...  0.002207  0.005911  0.013596   \n",
       "1  0.013888  0.020096  0.003213  0.013634  ...  0.001162  0.005886  0.013432   \n",
       "2  0.039497  0.011572  0.009824  0.009682  ...  0.003252  0.008721  0.011465   \n",
       "3  0.009848  0.014674  0.009491  0.006400  ...  0.004020  0.006802  0.017739   \n",
       "4  0.007631  0.005348  0.006919  0.006193  ...  0.000730  0.003299  0.009305   \n",
       "\n",
       "    yelbis1   yenspu1   yertin1   yesbar1   yespet1   yetgre1   yewgre1  \n",
       "0  0.002669  0.016673  0.006696  0.008719  0.003567  0.005940  0.007900  \n",
       "1  0.009267  0.034829  0.029104  0.020500  0.006882  0.010174  0.071354  \n",
       "2  0.009803  0.012738  0.037714  0.010992  0.013150  0.013500  0.035175  \n",
       "3  0.007555  0.027206  0.010791  0.022323  0.008253  0.017065  0.009040  \n",
       "4  0.008281  0.013102  0.012779  0.012167  0.005364  0.006497  0.009672  \n",
       "\n",
       "[5 rows x 265 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dicts = {}\n",
    "for d in dicts:\n",
    "    prediction_dicts.update(d)\n",
    "    \n",
    "submission = pd.DataFrame.from_dict(prediction_dicts, \"index\").rename_axis(\"row_id\").reset_index()\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(f\"\"\"\n",
    "total rows : {len(submission)}\n",
    "\"\"\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeee91f",
   "metadata": {
    "papermill": {
     "duration": 0.007173,
     "end_time": "2023-05-09T23:30:49.090664",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.083491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## my infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07f61927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:49.107484Z",
     "iopub.status.busy": "2023-05-09T23:30:49.107083Z",
     "iopub.status.idle": "2023-05-09T23:30:49.113243Z",
     "shell.execute_reply": "2023-05-09T23:30:49.112157Z"
    },
    "papermill": {
     "duration": 0.017565,
     "end_time": "2023-05-09T23:30:49.115565",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.098000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class BirdDataset(Dataset):\n",
    "#     def __init__(self, frame_length, sample_rate):\n",
    "#         self.frame_length = frame_length\n",
    "#         self.sample_rate = sample_rate\n",
    "#         self.data   = sorted(glob.glob(\"/kaggle/input/birdclef-2023/test_soundscapes/*.ogg\")) \n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         \"\"\"\n",
    "#         Prepare audio clip for inference\n",
    "#         \"\"\"\n",
    "#         fpath = self.data[idx]\n",
    "#         sample_rate = self.sample_rate\n",
    "#         frame_length = self.frame_length\n",
    "        \n",
    "#         infer_frame_length = frame_length\n",
    "#         batch = {\"wav_tensors\": [], \"end_times\": []}\n",
    "\n",
    "#         waveform, sample_rate = librosa.load(fpath, sr=sample_rate, mono=True)\n",
    "#         n_parts = math.ceil(len(waveform) / int(infer_frame_length * sample_rate))\n",
    "\n",
    "#         for seg_idx in range(n_parts): \n",
    "#             end_time = (seg_idx + 1) * frame_length\n",
    "#             seg_wav  = waveform[(end_time*sample_rate)-(sample_rate*frame_length):end_time*sample_rate]\n",
    "\n",
    "#             wav_tensor = torch.from_numpy(seg_wav)\n",
    "\n",
    "#             if len(wav_tensor) == frame_length * sample_rate:\n",
    "#                 batch[\"wav_tensors\"].append(wav_tensor.unsqueeze(0))\n",
    "#             elif len(wav_tensor) < frame_length * sample_rate:\n",
    "#                 wav_tensor = torch.nn.functional.pad(wav_tensor, (0, (frame_length * sample_rate) - len(wav_tensor)))\n",
    "#                 batch[\"wav_tensors\"].append(wav_tensor.unsqueeze(0))\n",
    "#             elif len(wav_tensor) > frame_length * sample_rate:\n",
    "#                 wav_tensor = wav_tensor[:(frame_length * sample_rate)]\n",
    "#                 batch[\"wav_tensors\"].append(wav_tensor.unsqueeze(0))\n",
    "\n",
    "#             batch[\"end_times\"].append(end_time)\n",
    "#         batch[\"wav_tensors\"] = torch.stack(batch[\"wav_tensors\"])\n",
    "#         return batch, n_parts, len(waveform)\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def predict_clip(models, batch, n_parts, frame_length):\n",
    "#     preds = np.zeros([len(models), n_parts, N_CLASS])\n",
    "#     for m_idx, model in enumerate(models):\n",
    "#         with torch.cuda.amp.autocast():\n",
    "#             preds[m_idx] = model(batch[\"wav_tensors\"], is_test=True)[\"logit\"].sigmoid().cpu().numpy()\n",
    "#     return preds.mean(0) ## max by model    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5a010c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:49.132145Z",
     "iopub.status.busy": "2023-05-09T23:30:49.131721Z",
     "iopub.status.idle": "2023-05-09T23:30:49.136955Z",
     "shell.execute_reply": "2023-05-09T23:30:49.135572Z"
    },
    "papermill": {
     "duration": 0.016195,
     "end_time": "2023-05-09T23:30:49.139265",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.123070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frame_length = 5\n",
    "# infer_frame_length = 5\n",
    "# sample_rate  = 32000\n",
    "# test_ds = BirdDataset(frame_length, sample_rate)\n",
    "\n",
    "# # loader = DataLoader(\n",
    "# #     test_ds,\n",
    "# #     batch_size=16, \n",
    "# #     num_workers=4,\n",
    "# #     drop_last=False,\n",
    "# #     shuffle=False,\n",
    "# #     pin_memory=True\n",
    "# # )\n",
    "\n",
    "# len(models), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c5d5140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:49.156226Z",
     "iopub.status.busy": "2023-05-09T23:30:49.155810Z",
     "iopub.status.idle": "2023-05-09T23:30:49.161395Z",
     "shell.execute_reply": "2023-05-09T23:30:49.160442Z"
    },
    "papermill": {
     "duration": 0.016793,
     "end_time": "2023-05-09T23:30:49.163489",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.146696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def generate_preds():\n",
    "#     debug = False\n",
    "#     preds        = []\n",
    "#     # test_files   = sorted(glob.glob(\"/kaggle/input/birdclef-2023/test_soundscapes/*.ogg\")) \n",
    "#     scored_birds = np.array(CLASSES)\n",
    "#     # print(\"test file num:\", len(test_files))\n",
    "    \n",
    "#     for batch, n_parts, len_waveform in tqdm(test_ds):\n",
    "#         # file_id = os.path.basename(fpath).replace(\".ogg\", \"\")\n",
    "#         # batch, n_parts, len_waveform = prepare_clip(fpath, frame_length, sample_rate)\n",
    "#         clip_preds = predict_clip(models, batch, n_parts, frame_length)\n",
    "#         preds.append(clip_preds)\n",
    "        \n",
    "#         ## switch to infer frame length\n",
    "#         n_parts_sub = math.ceil(len_waveform / int(infer_frame_length * sample_rate))\n",
    "#         clip_preds = np.array_split(clip_preds, n_parts_sub, axis=0)\n",
    "        \n",
    "                \n",
    "#     prob_array = np.array(preds)\n",
    "    \n",
    "#     scored_bird_name2idx = {}\n",
    "#     for i, x in enumerate(scored_birds):\n",
    "#         scored_bird_name2idx[x] = i\n",
    "\n",
    "#     return prob_array, scored_bird_name2idx\n",
    "\n",
    "# prob_array, scored_bird_name2idx = generate_preds()\n",
    "# # del models\n",
    "# # gc.collect()\n",
    "# # torch.cuda.empty_cache()\n",
    "# prob_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766caba6",
   "metadata": {
    "papermill": {
     "duration": 0.00688,
     "end_time": "2023-05-09T23:30:49.177725",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.170845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4901421c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:49.194383Z",
     "iopub.status.busy": "2023-05-09T23:30:49.193991Z",
     "iopub.status.idle": "2023-05-09T23:30:49.198161Z",
     "shell.execute_reply": "2023-05-09T23:30:49.197060Z"
    },
    "papermill": {
     "duration": 0.01524,
     "end_time": "2023-05-09T23:30:49.200128",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.184888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def generate_file_ids():\n",
    "#     test_files   = sorted(glob.glob(\"/kaggle/input/birdclef-2023/test_soundscapes/*.ogg\"))\n",
    "    \n",
    "#     file_ids = []\n",
    "    \n",
    "#     for fpath in test_files:\n",
    "#         file_id = os.path.basename(fpath).replace(\".ogg\", \"\")\n",
    "#         file_ids.append(file_id)\n",
    "        \n",
    "#     return file_ids\n",
    "\n",
    "# file_ids = generate_file_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ee3113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:49.216521Z",
     "iopub.status.busy": "2023-05-09T23:30:49.215545Z",
     "iopub.status.idle": "2023-05-09T23:30:49.220217Z",
     "shell.execute_reply": "2023-05-09T23:30:49.219306Z"
    },
    "papermill": {
     "duration": 0.015132,
     "end_time": "2023-05-09T23:30:49.222397",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.207265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## fix aniani\n",
    "# avg_preds = prob_array\n",
    "\n",
    "# avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12e7c5e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:49.239513Z",
     "iopub.status.busy": "2023-05-09T23:30:49.238877Z",
     "iopub.status.idle": "2023-05-09T23:30:49.243645Z",
     "shell.execute_reply": "2023-05-09T23:30:49.242726Z"
    },
    "papermill": {
     "duration": 0.015803,
     "end_time": "2023-05-09T23:30:49.245682",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.229879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission   = []\n",
    "# infer_frame_length = 5\n",
    "\n",
    "# for clip_preds, file_id in zip(avg_preds, file_ids):\n",
    "#     for frame_idx, pred in enumerate(clip_preds):\n",
    "#         end_time = (frame_idx + 1) * infer_frame_length\n",
    "#         d = {\n",
    "#             \"row_id\": f\"{file_id}_{end_time}\",\n",
    "#             # \"target\": pred[bi] > threshold,\n",
    "#         }\n",
    "#         for bi, bird in enumerate(CLASSES):\n",
    "#             d[bird] = pred[bi]\n",
    "#         submission.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "760529ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:49.262138Z",
     "iopub.status.busy": "2023-05-09T23:30:49.261740Z",
     "iopub.status.idle": "2023-05-09T23:30:49.266337Z",
     "shell.execute_reply": "2023-05-09T23:30:49.265083Z"
    },
    "papermill": {
     "duration": 0.015451,
     "end_time": "2023-05-09T23:30:49.268507",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.253056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d290913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:49.284772Z",
     "iopub.status.busy": "2023-05-09T23:30:49.284381Z",
     "iopub.status.idle": "2023-05-09T23:30:49.288938Z",
     "shell.execute_reply": "2023-05-09T23:30:49.287704Z"
    },
    "papermill": {
     "duration": 0.015335,
     "end_time": "2023-05-09T23:30:49.291134",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.275799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_submission = pd.DataFrame(submission).set_index(\"row_id\")\n",
    "# df_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2a166ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T23:30:49.307904Z",
     "iopub.status.busy": "2023-05-09T23:30:49.306872Z",
     "iopub.status.idle": "2023-05-09T23:30:49.312075Z",
     "shell.execute_reply": "2023-05-09T23:30:49.310960Z"
    },
    "papermill": {
     "duration": 0.015918,
     "end_time": "2023-05-09T23:30:49.314337",
     "exception": false,
     "start_time": "2023-05-09T23:30:49.298419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f\"\"\"\n",
    "# total rows : {len(df_submission)}\n",
    "# \"\"\")\n",
    "\n",
    "# df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 72.483683,
   "end_time": "2023-05-09T23:30:51.447778",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-09T23:29:38.964095",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
